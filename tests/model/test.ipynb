{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aitomatic/miniconda3/envs/kswe/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/aitomatic/src/github/h1st-ai/h1st/h1st/model/kswe')\n",
    "\n",
    "from kswe_modeler import KSWEModeler\n",
    "from segmentor import CombinationSegmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data():\n",
    "    df_raw = datasets.load_iris(as_frame=True).frame\n",
    "    df_raw.columns = ['sepal_length','sepal_width','petal_length','petal_width', 'species']\n",
    "    df_raw['sepal_size'] = df_raw['sepal_length'] * df_raw['sepal_width']\n",
    "    df_raw['sepal_aspect_ratio'] =  df_raw['sepal_width'] / df_raw['sepal_length'] \n",
    "    \n",
    "    X_cols = list(df_raw.columns)\n",
    "    # X_cols.remove('species')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_raw[X_cols], df_raw['species'], test_size=0.4, random_state=1)    \n",
    "    return {\n",
    "        'dataframe': {\n",
    "            'X_train': X_train, \n",
    "            'y_train': y_train, \n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "from h1st.model.ml_model import MLModel\n",
    "from h1st.model.ml_modeler import MLModeler\n",
    "from h1st.model.rule_based_modeler import RuleBasedModeler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as sk_metrics\n",
    "import pandas as pd\n",
    "\n",
    "from segmentor import CombinationSegmentor\n",
    "from ensemble import MajorityVotingEnsemble\n",
    "\n",
    "class MySubModel(MLModel):\n",
    "    def predict(self, input_data: Dict) -> Dict:\n",
    "        y = self.base_model.predict(input_data['X'])\n",
    "        return {'predictions': y}\n",
    "\n",
    "\n",
    "class MySubModelModeler(MLModeler):\n",
    "    def __init__(self, model_class=MySubModel):\n",
    "        self.model_class = model_class\n",
    "        self.stats = {}\n",
    "    \n",
    "    def evaluate_model(self, data: Dict, model: MLModel) -> Dict:\n",
    "        # super().evaluate_model(data, model)\n",
    "        if 'X_test' not in data:\n",
    "            print('No test data found. evaluating training results')\n",
    "            X, y_true = data['X_train'], data['y_train']\n",
    "        else:\n",
    "            X, y_true = data['X_test'], data['y_test']\n",
    "        y_pred = pd.Series(model.predict({'X': X})['predictions'])\n",
    "        return {'r2_score': sk_metrics.r2_score(y_true, y_pred)}\n",
    "\n",
    "    def train_base_model(self, data: Dict[str, Any]) -> Any:\n",
    "        X, y = data['X_train'], data['y_train']\n",
    "        model = LogisticRegression(random_state=0)\n",
    "        model.fit(X, y)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:sub model segment_0_lvl_1 training resluts based on 60 samples: {'r2_score': 0.9712092130518234}\n",
      "INFO:root:sub model segment_0_lvl_1 test resluts based on 60 samples: {'r2_score': 0.897392047883711}\n",
      "INFO:root:sub model segment_1_lvl_1 training resluts based on 30 samples: {'r2_score': 0.9424184261036468}\n",
      "INFO:root:sub model segment_1_lvl_1 test resluts based on 60 samples: {'r2_score': 0.9230440359127832}\n",
      "INFO:root:sub model segment_2_lvl_1 training resluts based on 68 samples: {'r2_score': 0.9384893713251923}\n",
      "INFO:root:sub model segment_2_lvl_1 test resluts based on 60 samples: {'r2_score': 0.9486960239418555}\n",
      "INFO:root:sub model segment_4_lvl_1 training resluts based on 60 samples: {'r2_score': 1.0}\n",
      "INFO:root:sub model segment_4_lvl_1 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "INFO:root:sub model segment_5_lvl_1 training resluts based on 59 samples: {'r2_score': 0.7965517241379311}\n",
      "INFO:root:sub model segment_5_lvl_1 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "INFO:root:sub model segment_6_lvl_2 training resluts based on 43 samples: {'r2_score': 0.9519015659955257}\n",
      "INFO:root:sub model segment_6_lvl_2 test resluts based on 60 samples: {'r2_score': 0.9230440359127832}\n",
      "INFO:root:sub model segment_10_lvl_2 training resluts based on 48 samples: {'r2_score': 1.0}\n",
      "INFO:root:sub model segment_10_lvl_2 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "INFO:root:sub model segment_11_lvl_2 training resluts based on 34 samples: {'r2_score': 0.7424242424242424}\n",
      "INFO:root:sub model segment_11_lvl_2 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "INFO:root:sub model segment_14_lvl_2 training resluts based on 38 samples: {'r2_score': 1.0}\n",
      "INFO:root:sub model segment_14_lvl_2 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "INFO:root:sub model segment_15_lvl_2 training resluts based on 59 samples: {'r2_score': 0.7965517241379311}\n",
      "INFO:root:sub model segment_15_lvl_2 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "INFO:root:sub model segment_18_lvl_3 training resluts based on 31 samples: {'r2_score': 1.0}\n",
      "INFO:root:sub model segment_18_lvl_3 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "INFO:root:sub model segment_19_lvl_3 training resluts based on 34 samples: {'r2_score': 0.7424242424242424}\n",
      "INFO:root:sub model segment_19_lvl_3 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No test data found. evaluating training results\n",
      "No test data found. evaluating training results\n",
      "No test data found. evaluating training results\n",
      "No test data found. evaluating training results\n",
      "No test data found. evaluating training results\n",
      "No test data found. evaluating training results\n",
      "No test data found. evaluating training results\n",
      "No test data found. evaluating training results\n",
      "No test data found. evaluating training results\n",
      "No test data found. evaluating training results\n",
      "No test data found. evaluating training results\n",
      "No test data found. evaluating training results\n",
      "kswe test results {'r2_score': 0.9486960239418555}\n"
     ]
    }
   ],
   "source": [
    "data = load_data()\n",
    "segmentation_features = {\n",
    "    'sepal_size': [(None, 18.5), (18.5, None)],\n",
    "    'sepal_aspect_ratio': [(None, 0.65), (0.65, None)],\n",
    "    'species': [[0, 1], [1, 2]]\n",
    "}\n",
    "kswe_modeler = KSWEModeler()\n",
    "kswe = kswe_modeler.build_model(\n",
    "    input_data=data,\n",
    "    segmentation_features=segmentation_features, \n",
    "    min_data_size=30,\n",
    "    segmentor=CombinationSegmentor(), \n",
    "    sub_model_modeler=MySubModelModeler(),\n",
    "    ensemble_modeler=RuleBasedModeler(model_class=MajorityVotingEnsemble)\n",
    ")\n",
    "X_features = list(data['dataframe']['X_test'].columns)\n",
    "for item in segmentation_features.keys(): X_features.remove(item)\n",
    "\n",
    "pred = kswe.predict({'X': data['dataframe']['X_test'][X_features]})['predictions']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:h1st.model.repository.model_repository:Model persistence currently supports only stats, model and metrics properties.\n",
      "INFO:h1st.model.repository.model_repository:Make sure you store stastistic in stats property, models in model property and model metrics in metrics one.\n",
      "INFO:h1st.model.repository.model_repository:Saving metrics property...\n",
      "INFO:h1st.model.repository.model_repository:Saving stats property...\n",
      "INFO:h1st.model.repository.model_repository:Saving model property...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r2_score': 0.9486960239418555}\n",
      "my_v1_segment_0_lvl_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:h1st.model.repository.model_repository:Saving metrics property...\n",
      "INFO:h1st.model.repository.model_repository:Saving stats property...\n",
      "INFO:h1st.model.repository.model_repository:Saving model property...\n",
      "INFO:h1st.model.repository.model_repository:Saving metrics property...\n",
      "INFO:h1st.model.repository.model_repository:Saving stats property...\n",
      "INFO:h1st.model.repository.model_repository:Saving model property...\n",
      "INFO:h1st.model.repository.model_repository:Saving metrics property...\n",
      "INFO:h1st.model.repository.model_repository:Saving stats property...\n",
      "INFO:h1st.model.repository.model_repository:Saving model property...\n",
      "INFO:h1st.model.repository.model_repository:Saving metrics property...\n",
      "INFO:h1st.model.repository.model_repository:Saving stats property...\n",
      "INFO:h1st.model.repository.model_repository:Saving model property...\n",
      "INFO:h1st.model.repository.model_repository:Saving metrics property...\n",
      "INFO:h1st.model.repository.model_repository:Saving stats property...\n",
      "INFO:h1st.model.repository.model_repository:Saving model property...\n",
      "INFO:h1st.model.repository.model_repository:Saving metrics property...\n",
      "INFO:h1st.model.repository.model_repository:Saving stats property...\n",
      "INFO:h1st.model.repository.model_repository:Saving model property...\n",
      "INFO:h1st.model.repository.model_repository:Saving metrics property...\n",
      "INFO:h1st.model.repository.model_repository:Saving stats property...\n",
      "INFO:h1st.model.repository.model_repository:Saving model property...\n",
      "INFO:h1st.model.repository.model_repository:Saving metrics property...\n",
      "INFO:h1st.model.repository.model_repository:Saving stats property...\n",
      "INFO:h1st.model.repository.model_repository:Saving model property...\n",
      "INFO:h1st.model.repository.model_repository:Saving metrics property...\n",
      "INFO:h1st.model.repository.model_repository:Saving stats property...\n",
      "INFO:h1st.model.repository.model_repository:Saving model property...\n",
      "INFO:h1st.model.repository.model_repository:Saving metrics property...\n",
      "INFO:h1st.model.repository.model_repository:Saving stats property...\n",
      "INFO:h1st.model.repository.model_repository:Saving model property...\n",
      "INFO:h1st.model.repository.model_repository:Saving metrics property...\n",
      "INFO:h1st.model.repository.model_repository:Saving stats property...\n",
      "INFO:h1st.model.repository.model_repository:Saving model property...\n",
      "INFO:h1st.model.repository.model_repository:Saving metrics property...\n",
      "INFO:h1st.model.repository.model_repository:Saving stats property...\n",
      "INFO:h1st.model.repository.model_repository:Loading version my_v1 ....\n",
      "INFO:h1st.model.repository.model_repository:Loading version my_v1_ensemble ....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_v1_segment_1_lvl_1\n",
      "my_v1_segment_2_lvl_1\n",
      "my_v1_segment_4_lvl_1\n",
      "my_v1_segment_5_lvl_1\n",
      "my_v1_segment_6_lvl_2\n",
      "my_v1_segment_10_lvl_2\n",
      "my_v1_segment_11_lvl_2\n",
      "my_v1_segment_14_lvl_2\n",
      "my_v1_segment_15_lvl_2\n",
      "my_v1_segment_18_lvl_3\n",
      "my_v1_segment_19_lvl_3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'MySubModel' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/aitomatic/src/github/h1st-ai/h1st/tests/model/test.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aitomatic/src/github/h1st-ai/h1st/tests/model/test.ipynb#ch0000056?line=15'>16</a>\u001b[0m kswe \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aitomatic/src/github/h1st-ai/h1st/tests/model/test.ipynb#ch0000056?line=16'>17</a>\u001b[0m kswe \u001b[39m=\u001b[39m KSWE(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aitomatic/src/github/h1st-ai/h1st/tests/model/test.ipynb#ch0000056?line=17'>18</a>\u001b[0m     segmentor\u001b[39m=\u001b[39mCombinationSegmentor(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aitomatic/src/github/h1st-ai/h1st/tests/model/test.ipynb#ch0000056?line=18'>19</a>\u001b[0m     sub_model\u001b[39m=\u001b[39mMySubModel(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aitomatic/src/github/h1st-ai/h1st/tests/model/test.ipynb#ch0000056?line=19'>20</a>\u001b[0m     ensemble\u001b[39m=\u001b[39mMajorityVotingEnsemble()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aitomatic/src/github/h1st-ai/h1st/tests/model/test.ipynb#ch0000056?line=20'>21</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aitomatic/src/github/h1st-ai/h1st/tests/model/test.ipynb#ch0000056?line=21'>22</a>\u001b[0m kswe\u001b[39m.\u001b[39;49mload_params(\u001b[39m'\u001b[39;49m\u001b[39mmy_v1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aitomatic/src/github/h1st-ai/h1st/tests/model/test.ipynb#ch0000056?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(test_kswe(kswe, data[\u001b[39m'\u001b[39m\u001b[39mdataframe\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "File \u001b[0;32m~/src/github/h1st-ai/h1st/h1st/model/kswe/kswe.py:52\u001b[0m, in \u001b[0;36mKSWE.load_params\u001b[0;34m(self, version)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/aitomatic/src/github/h1st-ai/h1st/h1st/model/kswe/kswe.py?line=49'>50</a>\u001b[0m sub_models \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='file:///Users/aitomatic/src/github/h1st-ai/h1st/h1st/model/kswe/kswe.py?line=50'>51</a>\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m sub_model_names:\n\u001b[0;32m---> <a href='file:///Users/aitomatic/src/github/h1st-ai/h1st/h1st/model/kswe/kswe.py?line=51'>52</a>\u001b[0m     sub_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msub_model_class()\u001b[39m.\u001b[39mload_params(version\u001b[39m+\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='file:///Users/aitomatic/src/github/h1st-ai/h1st/h1st/model/kswe/kswe.py?line=52'>53</a>\u001b[0m     sub_models[name] \u001b[39m=\u001b[39m sub_model\n\u001b[1;32m     <a href='file:///Users/aitomatic/src/github/h1st-ai/h1st/h1st/model/kswe/kswe.py?line=53'>54</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msub_models \u001b[39m=\u001b[39m sub_models\n",
      "\u001b[0;31mTypeError\u001b[0m: 'MySubModel' object is not callable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from kswe import KSWE\n",
    "\n",
    "def test_kswe(kswe, data):\n",
    "    X, y_true = data['X_test'], data['y_test']\n",
    "    y_pred = pd.Series(kswe.predict({'X': X})['predictions'])\n",
    "    return {'r2_score': metrics.r2_score(y_true, y_pred)}   \n",
    "    \n",
    "\n",
    "with tempfile.TemporaryDirectory() as path:\n",
    "    os.environ['H1ST_MODEL_REPO_PATH'] = path\n",
    "    print(test_kswe(kswe, data['dataframe']))\n",
    "    kswe.persist('my_v1')\n",
    "\n",
    "    kswe = None\n",
    "    kswe = KSWE(\n",
    "        segmentor=CombinationSegmentor(),\n",
    "        sub_model=MySubModel,\n",
    "        ensemble=MajorityVotingEnsemble()\n",
    "    )\n",
    "    kswe.load_params('my_v1')\n",
    "    print(test_kswe(kswe, data['dataframe']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub model segment_0_lvl_1 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "sub model segment_1_lvl_1 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "sub model segment_2_lvl_1 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "sub model segment_4_lvl_1 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "sub model segment_5_lvl_1 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "sub model segment_6_lvl_2 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "sub model segment_10_lvl_2 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "sub model segment_11_lvl_2 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "sub model segment_14_lvl_2 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "sub model segment_15_lvl_2 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "sub model segment_18_lvl_3 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n",
      "sub model segment_19_lvl_3 test resluts based on 60 samples: {'r2_score': 0.4869602394185548}\n"
     ]
    }
   ],
   "source": [
    "test_data = {\n",
    "    'X_test': data['dataframe']['X_test'][X_features],\n",
    "    'y_test': data['dataframe']['y_test']\n",
    "}\n",
    "for name, model in kswe.sub_models.items():\n",
    "    \n",
    "    metrics = MySubModelModeler().evaluate_model(test_data, model)\n",
    "    print(f'sub model {name} test resluts based on {test_data[\"X_test\"].shape[0]} samples: {metrics}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MySubModel at 0x7f9489639820>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kswe.sub_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/aitomatic/src/github/h1st-ai/h1st/tests/model/test.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aitomatic/src/github/h1st-ai/h1st/tests/model/test.ipynb#ch0000063?line=0'>1</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X_train', 'y_train', 'X_test', 'y_test'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['dataframe'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'dataframe' not in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'key \"dataframe\" or \"json\" is not in your input_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/aitomatic/src/github/h1st-ai/h1st/tests/model/test.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aitomatic/src/github/h1st-ai/h1st/tests/model/test.ipynb#ch0000044?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mdataframe\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m data \u001b[39mor\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m data:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aitomatic/src/github/h1st-ai/h1st/tests/model/test.ipynb#ch0000044?line=1'>2</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mkey \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdataframe\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m or \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m is not in your input_data\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'key \"dataframe\" or \"json\" is not in your input_data'"
     ]
    }
   ],
   "source": [
    "if 'dataframe' not in data or 'json' not in data:\n",
    "    raise KeyError('key \"dataframe\" or \"json\" is not in your input_data')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_0['sepal_aspect_ratio'].hist(bins=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_0['sepal_size'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_features = {\n",
    "    'sepal_size': [(None, 18.5), (18.5, None)],\n",
    "    'sepal_aspect_ratio': [(None, 0.65), (0.65, None)],\n",
    "    # 'species': [[0]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = CombinationSegmentor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "\n",
    "results, filter_combinations = cs.process(\n",
    "    data, \n",
    "    by=segmentation_features,\n",
    "    min_data_size=40,\n",
    "    levels=[2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sepal_size', (None, 18.5)), ('sepal_aspect_ratio', (None, 0.65))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_combinations['segment_0_lvl_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment_0_lvl_2 (69, 4)\n",
      "segment_2_lvl_2 (44, 4)\n"
     ]
    }
   ],
   "source": [
    "for k, v in results.items():\n",
    "    print(k, v['X'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segment_0_lvl_2': [('sepal_size', (None, 18.5)),\n",
       "  ('sepal_aspect_ratio', (None, 0.65))],\n",
       " 'segment_1_lvl_2': [('sepal_size', (None, 18.5)),\n",
       "  ('sepal_aspect_ratio', (0.65, None))],\n",
       " 'segment_2_lvl_2': [('sepal_size', (18.5, None)),\n",
       "  ('sepal_aspect_ratio', (None, 0.65))],\n",
       " 'segment_3_lvl_2': [('sepal_size', (18.5, None)),\n",
       "  ('sepal_aspect_ratio', (0.65, None))]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {'df': 2, 'ddd': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(temp.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = results['segment_0_lvl_2'].iloc[:, :-1]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['species'].loc[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_coco(file, info, licenses, images, annotations, categories):\n",
    "    with open(file, 'wt', encoding='UTF-8') as coco:\n",
    "        json.dump({'info': info, 'licenses': licenses, 'images': images,\n",
    "                   'annotations': annotations, 'categories': categories}, coco, indent=2, sort_keys=True)\n",
    "\n",
    "    \n",
    "def filter_annotations(annotations, images):\n",
    "    image_ids = funcy.lmap(lambda i: int(i['id']), images)\n",
    "    return funcy.lfilter(lambda a: int(a['image_id']) in image_ids, annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(args):\n",
    "    with open(args.annotations, 'rt', encoding='UTF-8') as annotations:\n",
    "        coco = json.load(annotations)\n",
    "        info = coco['info']\n",
    "        licenses = coco['licenses']\n",
    "        images = coco['images']\n",
    "        annotations = coco['annotations']\n",
    "        categories = coco['categories']\n",
    "\n",
    "        number_of_images = len(images)\n",
    "\n",
    "        images_with_annotations = funcy.lmap(lambda a: int(a['image_id']), annotations)\n",
    "\n",
    "        if args.having_annotations:\n",
    "            images = funcy.lremove(lambda i: i['id'] not in images_with_annotations, images)\n",
    "\n",
    "        x, y = train_test_split(images, train_size=args.split)\n",
    "\n",
    "        save_coco(args.train, info, licenses, x, filter_annotations(annotations, x), categories)\n",
    "        save_coco(args.test, info, licenses, y, filter_annotations(annotations, y), categories)\n",
    "\n",
    "        print(\"Saved {} entries in {} and {} in {}\".format(len(x), args.train, len(y), args.test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_path = '/Users/aitomatic/Desktop/dataset/furuno/sample_15mins/annotations.json'\n",
    "with open(data_path, 'r', encoding='UTF-8') as annotations:\n",
    "    coco = json.load(annotations)\n",
    "info = coco['info']\n",
    "licenses = coco['licenses']\n",
    "images = coco['images']\n",
    "annotations = coco['annotations']\n",
    "categories = coco['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_example = filter_combinations['segment_0_lvl_2']\n",
    "logic_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import funcy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. create new features and save that in annotation\n",
    "ex) \n",
    "- depth_of_bb\n",
    "- aspect_ratio_of_bb\n",
    "- size_of_bb\n",
    "- datetime\n",
    "\n",
    "2. make logics in this format. [('depth_of_bb', (None, 200)), ('aspect_ratio_of_bb', (None, 0.65))]\n",
    "\n",
    "3. make a function get_segments_from_json(JSON, segmentation_logics) -> return segmented JSONs\n",
    "- make sure images, annotations, and categories are synchronized. \n",
    "\n",
    "4. save those JSONs and move around files based on that json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_features():\n",
    "    annotation_json_path = '/Users/aitomatic/Desktop/dataset/furuno/sample_15mins/annotations.json'\n",
    "    with open(annotation_json_path, 'r', encoding='UTF-8') as annotations:\n",
    "        coco = json.load(annotations)\n",
    "    info = coco['info']\n",
    "    licenses = coco['licenses']\n",
    "    images = coco['images']\n",
    "    annotations = coco['annotations']\n",
    "    categories = coco['categories']\n",
    "\n",
    "    for idx in range(len(annotations)):\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f6a46fe09d9ec9696a1ed54afe90488c02227ac218767da890cc8e5601fffd4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('kswe')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
